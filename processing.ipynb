{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "## Remove Rows and Sample Randomly\n",
    "\n",
    "We will now drop any rows that are irrelevant to us and save it to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2896109</th>\n",
       "      <td>Best edition of this classic.</td>\n",
       "      <td>I've always recommended this Yale edition of F...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381153</th>\n",
       "      <td>Great Book!!</td>\n",
       "      <td>This is required reading for my 16 yr old son....</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028690</th>\n",
       "      <td>Not just a book for consultant</td>\n",
       "      <td>Plain-spoken, finished the book only has taken...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945977</th>\n",
       "      <td>Outrageously Bad</td>\n",
       "      <td>Wow... this is one of the most ridiculous stor...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2812693</th>\n",
       "      <td>Cunning and determination</td>\n",
       "      <td>A crew has mutinied and threatens to hang thei...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                summary  \\\n",
       "2896109   Best edition of this classic.   \n",
       "2381153                    Great Book!!   \n",
       "1028690  Not just a book for consultant   \n",
       "1945977                Outrageously Bad   \n",
       "2812693       Cunning and determination   \n",
       "\n",
       "                                                      text  score  \n",
       "2896109  I've always recommended this Yale edition of F...    5.0  \n",
       "2381153  This is required reading for my 16 yr old son....    5.0  \n",
       "1028690  Plain-spoken, finished the book only has taken...    4.0  \n",
       "1945977  Wow... this is one of the most ridiculous stor...    1.0  \n",
       "2812693  A crew has mutinied and threatens to hang thei...    4.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv('data/Books_rating.csv')\n",
    "\n",
    "# only preserve 'review/summary', 'review/text', and 'review/score' columns\n",
    "df = df[['review/summary', 'review/text', 'review/score']]\n",
    "\n",
    "# rename columns\n",
    "df.columns = ['summary', 'text', 'score']\n",
    "\n",
    "# choose 1 million random rows\n",
    "df = df.sample(n=1000000, random_state=1)\n",
    "\n",
    "# save to new csv file\n",
    "df.to_csv('data/Books_rating_relevant_columns.csv', index=False)\n",
    "\n",
    "# print first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords, Lemmatization, and Vectorization\n",
    "\n",
    "Process the text to remove stopwords, lemmatize, strip unneeded characters, then vectorize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [06:19<00:00, 2632.95it/s]\n",
      "100%|██████████| 1000000/1000000 [00:33<00:00, 29445.70it/s]\n",
      "100%|██████████| 1000000/1000000 [00:00<00:00, 2907145.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>stemmed_summary_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>best edition classic always recommended yale e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>great book required reading 16 yr old son book...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>book consultant plain spoken finished book tak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>outrageously bad wow one ridiculous story ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>cunning determination crew mutinied threatens ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score                               stemmed_summary_text\n",
       "0    5.0  best edition classic always recommended yale e...\n",
       "1    5.0  great book required reading 16 yr old son book...\n",
       "2    4.0  book consultant plain spoken finished book tak...\n",
       "3    1.0  outrageously bad wow one ridiculous story ever...\n",
       "4    4.0  cunning determination crew mutinied threatens ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def stemmer(text):\n",
    "  if text != text:\n",
    "    return ''\n",
    "  \n",
    "  # replace non-alphanumeric characters with space\n",
    "  text = re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
    "\n",
    "  # remove multiple spaces\n",
    "  text = re.sub(' +', ' ', text)\n",
    "\n",
    "  # # lowercase\n",
    "  text = text.lower()\n",
    "\n",
    "  # tokenize\n",
    "  tokens = word_tokenize(text)\n",
    "\n",
    "  # remove stopwords\n",
    "  tokens = [w for w in tokens if not w in stopwords]\n",
    "\n",
    "  # lemmatize\n",
    "  tokens = [lemmatizer.lemmatize(w) for w in tokens]\n",
    "\n",
    "  # join tokens\n",
    "  text = ' '.join(tokens)\n",
    "\n",
    "  return text\n",
    "\n",
    "# load df\n",
    "df = pd.read_csv('data/Books_rating_relevant_columns.csv')\n",
    "\n",
    "# apply stemmer to text\n",
    "df['stemmed_text'] = df['text'].progress_apply(stemmer)\n",
    "df['stemmed_summary'] = df['summary'].progress_apply(stemmer)\n",
    "df['stemmed_summary_text'] = df['stemmed_summary'] + ' ' + df['stemmed_text']\n",
    "\n",
    "# remove trailing spaces\n",
    "df['stemmed_summary_text'] = df['stemmed_summary_text'].progress_apply(lambda x: x.strip())\n",
    "\n",
    "# replace NaN with empty string\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "# remove rows with empty stemmed_summary_text\n",
    "df = df[df['stemmed_summary_text'] != '']\n",
    "\n",
    "# drop unused columns\n",
    "df.drop(columns=['text', 'summary', 'stemmed_summary', 'stemmed_text'], inplace=True)\n",
    "\n",
    "# save to new csv file\n",
    "df.to_csv('data/Books_rating_stemmed.csv', index=False)\n",
    "\n",
    "# print first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing\n",
    "\n",
    "Vectorize the text using TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999999, 2)\n",
      "Vectorizer saved\n",
      "(799999, 30000)\n",
      "(200000, 30000)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "df = pd.read_csv('data/Books_rating_stemmed.csv')\n",
    "print(df.shape)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=30_000, sublinear_tf=True)\n",
    "\n",
    "# create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['stemmed_summary_text'], df['score'], test_size=0.2, random_state=1)\n",
    "\n",
    "# fit vectorizer on training set\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "# transform training and test sets\n",
    "X_train = vectorizer.transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# save vectorizer to disk\n",
    "pickle.dump(vectorizer, open('models/vectorizer.pkl', 'wb'))\n",
    "print('Vectorizer saved')\n",
    "\n",
    "# get shape of training and test sets\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing\n",
    "\n",
    "Test the model using a variety of classifiers. For now, just Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression trained\n",
      "Accuracy: 0.694525\n",
      "MSE: 0.837745\n",
      "RMSE: 0.9152841088973412\n"
     ]
    }
   ],
   "source": [
    "# train using logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_regression = LogisticRegression(max_iter=1000, n_jobs=-1, solver='saga')\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "print('Logistic regression trained')\n",
    "\n",
    "# get accuracy, mse, and rmse\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "y_pred = logistic_regression.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('MSE:', mse)\n",
    "print('RMSE:', rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
