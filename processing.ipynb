{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "We will now drop any rows that are irrelevant to us and save it to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2896109</th>\n",
       "      <td>Best edition of this classic.</td>\n",
       "      <td>I've always recommended this Yale edition of F...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381153</th>\n",
       "      <td>Great Book!!</td>\n",
       "      <td>This is required reading for my 16 yr old son....</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028690</th>\n",
       "      <td>Not just a book for consultant</td>\n",
       "      <td>Plain-spoken, finished the book only has taken...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945977</th>\n",
       "      <td>Outrageously Bad</td>\n",
       "      <td>Wow... this is one of the most ridiculous stor...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2812693</th>\n",
       "      <td>Cunning and determination</td>\n",
       "      <td>A crew has mutinied and threatens to hang thei...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                summary  \\\n",
       "2896109   Best edition of this classic.   \n",
       "2381153                    Great Book!!   \n",
       "1028690  Not just a book for consultant   \n",
       "1945977                Outrageously Bad   \n",
       "2812693       Cunning and determination   \n",
       "\n",
       "                                                      text  score  \n",
       "2896109  I've always recommended this Yale edition of F...    5.0  \n",
       "2381153  This is required reading for my 16 yr old son....    5.0  \n",
       "1028690  Plain-spoken, finished the book only has taken...    4.0  \n",
       "1945977  Wow... this is one of the most ridiculous stor...    1.0  \n",
       "2812693  A crew has mutinied and threatens to hang thei...    4.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv('data/Books_rating.csv')\n",
    "\n",
    "# only preserve 'review/summary', 'review/text', and 'review/score' columns\n",
    "df = df[['review/summary', 'review/text', 'review/score']]\n",
    "\n",
    "# rename columns\n",
    "df.columns = ['summary', 'text', 'score']\n",
    "\n",
    "# choose 1 million random rows\n",
    "df = df.sample(n=1000000, random_state=1)\n",
    "\n",
    "# save to new csv file\n",
    "df.to_csv('data/Books_rating_relevant_columns.csv', index=False)\n",
    "\n",
    "# print first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the text to remove stopwards, lemmatize, strip unneeded characters, then vectorize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/phillip/Git/cs505-final-project/processing.ipynb Cell 4\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/phillip/Git/cs505-final-project/processing.ipynb#W4sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mdata/Books_rating_relevant_columns.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/phillip/Git/cs505-final-project/processing.ipynb#W4sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# apply stemmer to text\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/phillip/Git/cs505-final-project/processing.ipynb#W4sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mstemmed_text\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(stemmer)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/phillip/Git/cs505-final-project/processing.ipynb#W4sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mstemmed_summary\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39msummary\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(stemmer)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/phillip/Git/cs505-final-project/processing.ipynb#W4sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mstemmed_summary\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mstemmed_summary\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mstrip())\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/series.py:4760\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4626\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4627\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4632\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4633\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4634\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4635\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4636\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4751\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4752\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4753\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4754\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   4755\u001b[0m         func,\n\u001b[1;32m   4756\u001b[0m         convert_dtype\u001b[39m=\u001b[39;49mconvert_dtype,\n\u001b[1;32m   4757\u001b[0m         by_row\u001b[39m=\u001b[39;49mby_row,\n\u001b[1;32m   4758\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   4759\u001b[0m         kwargs\u001b[39m=\u001b[39;49mkwargs,\n\u001b[0;32m-> 4760\u001b[0m     )\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/apply.py:1207\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1204\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_compat()\n\u001b[1;32m   1206\u001b[0m \u001b[39m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1207\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/apply.py:1287\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[39m# row-wise access\u001b[39;00m\n\u001b[1;32m   1282\u001b[0m \u001b[39m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m \u001b[39m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m \u001b[39m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1285\u001b[0m \u001b[39m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m action \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39mdtype, CategoricalDtype) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1287\u001b[0m mapped \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_map_values(\n\u001b[1;32m   1288\u001b[0m     mapper\u001b[39m=\u001b[39;49mcurried, na_action\u001b[39m=\u001b[39;49maction, convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype\n\u001b[1;32m   1289\u001b[0m )\n\u001b[1;32m   1291\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1292\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1294\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mmap(mapper, na_action\u001b[39m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[39mreturn\u001b[39;00m algorithms\u001b[39m.\u001b[39;49mmap_array(arr, mapper, na_action\u001b[39m=\u001b[39;49mna_action, convert\u001b[39m=\u001b[39;49mconvert)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1812\u001b[0m values \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   1813\u001b[0m \u001b[39mif\u001b[39;00m na_action \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1814\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39;49mmap_infer(values, mapper, convert\u001b[39m=\u001b[39;49mconvert)\n\u001b[1;32m   1815\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1816\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1817\u001b[0m         values, mapper, mask\u001b[39m=\u001b[39misna(values)\u001b[39m.\u001b[39mview(np\u001b[39m.\u001b[39muint8), convert\u001b[39m=\u001b[39mconvert\n\u001b[1;32m   1818\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2920\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m/Users/phillip/Git/cs505-final-project/processing.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/phillip/Git/cs505-final-project/processing.ipynb#W4sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m tokens \u001b[39m=\u001b[39m [w \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m tokens \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m w \u001b[39min\u001b[39;00m stopwords]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/phillip/Git/cs505-final-project/processing.ipynb#W4sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# lemmatize\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/phillip/Git/cs505-final-project/processing.ipynb#W4sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m tokens \u001b[39m=\u001b[39m [lemmatizer\u001b[39m.\u001b[39;49mlemmatize(w) \u001b[39mfor\u001b[39;49;00m w \u001b[39min\u001b[39;49;00m tokens]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/phillip/Git/cs505-final-project/processing.ipynb#W4sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# join tokens\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/phillip/Git/cs505-final-project/processing.ipynb#W4sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(tokens)\n",
      "\u001b[1;32m/Users/phillip/Git/cs505-final-project/processing.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/phillip/Git/cs505-final-project/processing.ipynb#W4sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m tokens \u001b[39m=\u001b[39m [w \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m tokens \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m w \u001b[39min\u001b[39;00m stopwords]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/phillip/Git/cs505-final-project/processing.ipynb#W4sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# lemmatize\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/phillip/Git/cs505-final-project/processing.ipynb#W4sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m tokens \u001b[39m=\u001b[39m [lemmatizer\u001b[39m.\u001b[39;49mlemmatize(w) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m tokens]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/phillip/Git/cs505-final-project/processing.ipynb#W4sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# join tokens\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/phillip/Git/cs505-final-project/processing.ipynb#W4sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(tokens)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/nltk/stem/wordnet.py:45\u001b[0m, in \u001b[0;36mWordNetLemmatizer.lemmatize\u001b[0;34m(self, word, pos)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlemmatize\u001b[39m(\u001b[39mself\u001b[39m, word: \u001b[39mstr\u001b[39m, pos: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mn\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m     34\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Lemmatize `word` using WordNet's built-in morphy function.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39m    Returns the input word unchanged if it cannot be found in WordNet.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39m    :return: The lemma of `word`, for the given `pos`.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     lemmas \u001b[39m=\u001b[39m wn\u001b[39m.\u001b[39;49m_morphy(word, pos)\n\u001b[1;32m     46\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mmin\u001b[39m(lemmas, key\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m) \u001b[39mif\u001b[39;00m lemmas \u001b[39melse\u001b[39;00m word\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/nltk/corpus/reader/wordnet.py:2100\u001b[0m, in \u001b[0;36mWordNetCorpusReader._morphy\u001b[0;34m(self, form, pos, check_exceptions)\u001b[0m\n\u001b[1;32m   2097\u001b[0m         \u001b[39mreturn\u001b[39;00m filter_forms([form] \u001b[39m+\u001b[39m exceptions[form])\n\u001b[1;32m   2099\u001b[0m \u001b[39m# 1. Apply rules once to the input to get y1, y2, y3, etc.\u001b[39;00m\n\u001b[0;32m-> 2100\u001b[0m forms \u001b[39m=\u001b[39m apply_rules([form])\n\u001b[1;32m   2102\u001b[0m \u001b[39m# 2. Return all that are in the database (and check the original too)\u001b[39;00m\n\u001b[1;32m   2103\u001b[0m results \u001b[39m=\u001b[39m filter_forms([form] \u001b[39m+\u001b[39m forms)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/nltk/corpus/reader/wordnet.py:2076\u001b[0m, in \u001b[0;36mWordNetCorpusReader._morphy.<locals>.apply_rules\u001b[0;34m(forms)\u001b[0m\n\u001b[1;32m   2075\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_rules\u001b[39m(forms):\n\u001b[0;32m-> 2076\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m   2077\u001b[0m         form[: \u001b[39m-\u001b[39;49m\u001b[39mlen\u001b[39;49m(old)] \u001b[39m+\u001b[39;49m new\n\u001b[1;32m   2078\u001b[0m         \u001b[39mfor\u001b[39;49;00m form \u001b[39min\u001b[39;49;00m forms\n\u001b[1;32m   2079\u001b[0m         \u001b[39mfor\u001b[39;49;00m old, new \u001b[39min\u001b[39;49;00m substitutions\n\u001b[1;32m   2080\u001b[0m         \u001b[39mif\u001b[39;49;00m form\u001b[39m.\u001b[39;49mendswith(old)\n\u001b[1;32m   2081\u001b[0m     ]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/nltk/corpus/reader/wordnet.py:2080\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2075\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_rules\u001b[39m(forms):\n\u001b[1;32m   2076\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m   2077\u001b[0m         form[: \u001b[39m-\u001b[39m\u001b[39mlen\u001b[39m(old)] \u001b[39m+\u001b[39m new\n\u001b[1;32m   2078\u001b[0m         \u001b[39mfor\u001b[39;00m form \u001b[39min\u001b[39;00m forms\n\u001b[1;32m   2079\u001b[0m         \u001b[39mfor\u001b[39;00m old, new \u001b[39min\u001b[39;00m substitutions\n\u001b[0;32m-> 2080\u001b[0m         \u001b[39mif\u001b[39;00m form\u001b[39m.\u001b[39;49mendswith(old)\n\u001b[1;32m   2081\u001b[0m     ]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def stemmer(text):\n",
    "  if text != text:\n",
    "    return ''\n",
    "  \n",
    "  # replace non-alphanumeric characters with space\n",
    "  text = re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
    "\n",
    "  # remove multiple spaces\n",
    "  text = re.sub(' +', ' ', text)\n",
    "\n",
    "  # # lowercase\n",
    "  text = text.lower()\n",
    "\n",
    "  # tokenize\n",
    "  tokens = word_tokenize(text)\n",
    "\n",
    "  # remove stopwords\n",
    "  tokens = [w for w in tokens if not w in stopwords]\n",
    "\n",
    "  # lemmatize\n",
    "  tokens = [lemmatizer.lemmatize(w) for w in tokens]\n",
    "\n",
    "  # join tokens\n",
    "  text = ' '.join(tokens)\n",
    "\n",
    "  return text\n",
    "\n",
    "# load df\n",
    "df = pd.read_csv('data/Books_rating_relevant_columns.csv')\n",
    "\n",
    "# apply stemmer to text\n",
    "df['stemmed_text'] = df['text'].progress_apply(stemmer)\n",
    "df['stemmed_summary'] = df['summary'].progress_apply(stemmer)\n",
    "df['stemmed_summary_text'] = df['stemmed_summary'] + ' ' + df['stemmed_text']\n",
    "\n",
    "# remove trailing spaces\n",
    "df['stemmed_summary_text'] = df['stemmed_summary_text'].progress_apply(lambda x: x.strip())\n",
    "\n",
    "# replace NaN with empty string\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "# remove rows with empty stemmed_summary_text\n",
    "df = df[df['stemmed_summary_text'] != '']\n",
    "\n",
    "# drop unused columns\n",
    "df.drop(columns=['text', 'summary', 'stemmed_summary', 'stemmed_text'], inplace=True)\n",
    "\n",
    "# save to new csv file\n",
    "df.to_csv('data/Books_rating_stemmed.csv', index=False)\n",
    "\n",
    "# print first 5 rows\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
